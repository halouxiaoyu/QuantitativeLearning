#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç‰¹å¾å·¥ç¨‹æ¨¡å—
æž„å»ºæŠ€æœ¯æŒ‡æ ‡ç‰¹å¾ï¼Œä¸ºæœºå™¨å­¦ä¹ æ¨¡åž‹æä¾›è¾“å…¥
"""

import os
import pandas as pd
import numpy as np
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

class FeatureEngineer:
    """ç‰¹å¾å·¥ç¨‹å¸ˆ"""
    
    def __init__(self, data_dir='data', features_dir='features'):
        self.data_dir = data_dir
        self.features_dir = features_dir
        self.ensure_directories()
        
    def ensure_directories(self):
        """ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨"""
        os.makedirs(self.features_dir, exist_ok=True)
    
    def load_cleaned_data(self, stock_code):
        """åŠ è½½æ¸…æ´—åŽçš„æ•°æ®"""
        cleaned_dir = os.path.join(self.data_dir, 'cleaned', stock_code)
        if not os.path.exists(cleaned_dir):
            print(f"âŒ æ²¡æœ‰æ‰¾åˆ°æ¸…æ´—åŽçš„æ•°æ®: {stock_code}")
            return None
        
        # æŸ¥æ‰¾æœ€æ–°çš„æ•°æ®æ–‡ä»¶
        import glob
        pattern = f"{stock_code}_*.csv"
        files = glob.glob(os.path.join(cleaned_dir, pattern))
        
        if not files:
            print(f"âŒ æ²¡æœ‰æ‰¾åˆ°æ•°æ®æ–‡ä»¶: {stock_code}")
            return None
        
        # é€‰æ‹©æœ€æ–°çš„æ–‡ä»¶
        latest_file = max(files, key=os.path.getctime)
        print(f"ðŸ“‚ åŠ è½½æ•°æ®: {os.path.basename(latest_file)}")
        
        try:
            df = pd.read_csv(latest_file, index_col=0, parse_dates=True)
            print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {len(df)} æ¡è®°å½•")
            return df
        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return None
    
    def build_features(self, df):
        """æž„å»ºæŠ€æœ¯æŒ‡æ ‡ç‰¹å¾"""
        if df is None or df.empty:
            return None
        
        print(f"ðŸ”§ æž„å»ºç‰¹å¾: {len(df)} æ¡è®°å½•")
        
        # å¤åˆ¶æ•°æ®ï¼Œé¿å…ä¿®æ”¹åŽŸå§‹æ•°æ®
        feat = df.copy()
        
        # 1. ä»·æ ¼å˜åŒ–çŽ‡
        feat['pct_change'] = feat['close'].pct_change()
        
        # 2. ç§»åŠ¨å¹³å‡çº¿
        feat['ma5'] = feat['close'].rolling(window=5).mean()
        feat['ma10'] = feat['close'].rolling(window=10).mean()
        feat['ma20'] = feat['close'].rolling(window=20).mean()
        
        # 3. ä»·æ ¼ä¸Žç§»åŠ¨å¹³å‡çº¿çš„æ¯”çŽ‡
        feat['ma5_ratio'] = feat['close'] / feat['ma5']
        feat['ma10_ratio'] = feat['close'] / feat['ma10']
        feat['ma20_ratio'] = feat['close'] / feat['ma20']
        
        # 4. MACDæŒ‡æ ‡
        feat['ema12'] = feat['close'].ewm(span=12).mean()
        feat['ema26'] = feat['close'].ewm(span=26).mean()
        feat['macd_dif'] = feat['ema12'] - feat['ema26']
        feat['macd_dea'] = feat['macd_dif'].ewm(span=9).mean()
        feat['macd_hist'] = feat['macd_dif'] - feat['macd_dea']
        
        # 5. RSIæŒ‡æ ‡
        feat['rsi14'] = self._calculate_rsi(feat['close'], window=14)
        
        # 6. æ³¢åŠ¨çŽ‡æŒ‡æ ‡
        feat['volatility_10'] = feat['pct_change'].rolling(window=10).std()
        feat['volatility_20'] = feat['pct_change'].rolling(window=20).std()
        
        # 7. æˆäº¤é‡æŒ‡æ ‡
        feat['volume_ma5'] = feat['volume'].rolling(window=5).mean()
        feat['volume_ratio'] = feat['volume'] / feat['volume_ma5']
        
        # 8. å¸ƒæž—å¸¦
        feat['bb_upper'] = feat['ma20'] + 2 * feat['close'].rolling(window=20).std()
        feat['bb_lower'] = feat['ma20'] - 2 * feat['close'].rolling(window=20).std()
        feat['bb_position'] = (feat['close'] - feat['bb_lower']) / (feat['bb_upper'] - feat['bb_lower'])
        
        # 9. åŠ¨é‡æŒ‡æ ‡
        feat['momentum_5'] = feat['close'] / feat['close'].shift(5) - 1
        feat['momentum_10'] = feat['close'] / feat['close'].shift(10) - 1
        
        # 10. ä»·æ ¼ä½ç½®æŒ‡æ ‡
        feat['high_low_ratio'] = (feat['high'] - feat['low']) / feat['close']
        feat['open_close_ratio'] = feat['open'] / feat['close']
        
        # 11. è¶‹åŠ¿æŒ‡æ ‡
        feat['trend_5'] = np.where(feat['ma5'] > feat['ma5'].shift(1), 1, -1)
        feat['trend_10'] = np.where(feat['ma10'] > feat['ma10'].shift(1), 1, -1)
        feat['trend_20'] = np.where(feat['ma20'] > feat['ma20'].shift(1), 1, -1)
        
        # 12. äº¤å‰ä¿¡å·
        feat['ma5_cross_ma10'] = np.where(
            (feat['ma5'] > feat['ma10']) & (feat['ma5'].shift(1) <= feat['ma10'].shift(1)), 1, 0)
        feat['ma10_cross_ma20'] = np.where(
            (feat['ma10'] > feat['ma20']) & (feat['ma10'].shift(1) <= feat['ma20'].shift(1)), 1, 0)
        
        # 13. æ”¯æ’‘é˜»åŠ›ä½
        feat['support_level'] = feat['low'].rolling(window=20).min()
        feat['resistance_level'] = feat['high'].rolling(window=20).max()
        feat['support_distance'] = (feat['close'] - feat['support_level']) / feat['close']
        feat['resistance_distance'] = (feat['resistance_level'] - feat['close']) / feat['close']
        
        # 14. ä»·æ ¼é€šé“
        feat['price_channel_high'] = feat['high'].rolling(window=20).max()
        feat['price_channel_low'] = feat['low'].rolling(window=20).min()
        feat['price_channel_position'] = (feat['close'] - feat['price_channel_low']) / (feat['price_channel_high'] - feat['price_channel_low'])
        
        # 15. æˆäº¤é‡ä»·æ ¼å…³ç³»
        feat['volume_price_trend'] = (feat['volume'] * feat['pct_change']).rolling(window=10).sum()
        
        # 16. ä»·æ ¼å˜åŒ–çŽ‡ç‰¹å¾ï¼ˆæ–°å¢žï¼‰
        feat['price_change'] = feat['close'].pct_change()
        feat['price_change_2'] = feat['close'].pct_change(2)
        feat['price_change_5'] = feat['close'].pct_change(5)
        
        # 17. æˆäº¤é‡å˜åŒ–ç‰¹å¾ï¼ˆæ–°å¢žï¼‰
        feat['volume_change'] = feat['volume'].pct_change()
        feat['volume_ma_ratio'] = feat['volume'] / feat['volume'].rolling(5).mean()
        
        # ç§»é™¤åŒ…å«NaNçš„è¡Œ
        initial_count = len(feat)
        feat = feat.dropna()
        print(f"   ç‰¹å¾æž„å»ºå®Œæˆ: {initial_count} -> {len(feat)} æ¡è®°å½•")
        
        # æ·»åŠ å…ƒæ•°æ®
        feat.attrs['stock_code'] = df.attrs.get('stock_code', 'unknown')
        feat.attrs['feature_count'] = len(feat.columns)
        feat.attrs['feature_names'] = list(feat.columns)
        feat.attrs['build_date'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        return feat
    
    def _calculate_rsi(self, prices, window=14):
        """è®¡ç®—RSIæŒ‡æ ‡"""
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        return rsi
    
    def save_features(self, feat, stock_code):
        """ä¿å­˜ç‰¹å¾æ•°æ®"""
        if feat is None or feat.empty:
            print(f"âŒ æ²¡æœ‰ç‰¹å¾æ•°æ®å¯ä¿å­˜: {stock_code}")
            return False
        
        try:
            # åˆ›å»ºè‚¡ç¥¨å­ç›®å½•
            stock_dir = os.path.join(self.features_dir, stock_code)
            os.makedirs(stock_dir, exist_ok=True)
            
            # ç”Ÿæˆæ–‡ä»¶å
            start_date = feat.index.min().strftime('%Y%m%d')
            end_date = feat.index.max().strftime('%Y%m%d')
            filename = f"{stock_code}_features_{start_date}_{end_date}.csv"
            filepath = os.path.join(stock_dir, filename)
            
            # ä¿å­˜CSVæ–‡ä»¶
            feat.to_csv(filepath, encoding='utf-8')
            
            # ä¿å­˜ç‰¹å¾ä¿¡æ¯
            feature_info = {
                'stock_code': stock_code,
                'feature_count': len(feat.columns),
                'feature_names': list(feat.columns),
                'data_points': len(feat),
                'date_range': f"{start_date} åˆ° {end_date}",
                'build_date': feat.attrs.get('build_date', datetime.now().strftime('%Y-%m-%d %H:%M:%S')),
                'file_path': filepath
            }
            
            info_file = os.path.join(stock_dir, f"{stock_code}_feature_info.json")
            import json
            with open(info_file, 'w', encoding='utf-8') as f:
                json.dump(feature_info, f, ensure_ascii=False, indent=2)
            
            print(f"   ðŸ’¾ ç‰¹å¾å·²ä¿å­˜: {filepath}")
            print(f"   ðŸ“Š ç‰¹å¾ä¿¡æ¯å·²ä¿å­˜: {info_file}")
            
            return True
            
        except Exception as e:
            print(f"âŒ ä¿å­˜ç‰¹å¾å¤±è´¥: {e}")
            return False
    
    def batch_build_features(self, stock_list=None, pool_name='all'):
        """æ‰¹é‡æž„å»ºç‰¹å¾"""
        if stock_list is None:
            # ä»Žæ•°æ®ç›®å½•èŽ·å–è‚¡ç¥¨åˆ—è¡¨
            cleaned_dir = os.path.join(self.data_dir, 'cleaned')
            if os.path.exists(cleaned_dir):
                stock_list = [d for d in os.listdir(cleaned_dir) if os.path.isdir(os.path.join(cleaned_dir, d))]
            else:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°æ¸…æ´—åŽçš„æ•°æ®ç›®å½•")
                return {}
        
        if not stock_list:
            print("âŒ æ²¡æœ‰è‚¡ç¥¨å¯å¤„ç†")
            return {}
        
        print(f"ðŸš€ å¼€å§‹æ‰¹é‡æž„å»ºç‰¹å¾: {len(stock_list)} åªè‚¡ç¥¨")
        print("=" * 60)
        
        results = {}
        success_count = 0
        
        for i, stock_code in enumerate(stock_list, 1):
            print(f"\nðŸ”§ [{i}/{len(stock_list)}] å¤„ç†è‚¡ç¥¨: {stock_code}")
            print("-" * 40)
            
            try:
                # åŠ è½½æ•°æ®
                df = self.load_cleaned_data(stock_code)
                
                if df is not None and not df.empty:
                    # æž„å»ºç‰¹å¾
                    feat = self.build_features(df)
                    
                    if feat is not None and not feat.empty:
                        # ä¿å­˜ç‰¹å¾
                        if self.save_features(feat, stock_code):
                            results[stock_code] = {
                                'status': 'success',
                                'feature_count': len(feat.columns),
                                'data_points': len(feat),
                                'date_range': f"{feat.index.min().strftime('%Y-%m-%d')} åˆ° {feat.index.max().strftime('%Y-%m-%d')}"
                            }
                            success_count += 1
                        else:
                            results[stock_code] = {'status': 'save_failed'}
                    else:
                        results[stock_code] = {'status': 'feature_build_failed'}
                else:
                    results[stock_code] = {'status': 'data_load_failed'}
                    
            except Exception as e:
                print(f"   âŒ å¤„ç†å¤±è´¥: {e}")
                results[stock_code] = {'status': 'error', 'error': str(e)}
            
            print(f"   {'âœ…' if results[stock_code]['status'] == 'success' else 'âŒ'} {stock_code}")
        
        # ç”Ÿæˆç‰¹å¾æž„å»ºæŠ¥å‘Š
        self._generate_feature_report(results)
        
        print(f"\nðŸŽ‰ æ‰¹é‡ç‰¹å¾æž„å»ºå®Œæˆ!")
        print(f"   æˆåŠŸ: {success_count}/{len(stock_list)}")
        print(f"   å¤±è´¥: {len(stock_list) - success_count}/{len(stock_list)}")
        
        return results
    
    def _generate_feature_report(self, results):
        """ç”Ÿæˆç‰¹å¾æž„å»ºæŠ¥å‘Š"""
        try:
            report = {
                'build_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'total_stocks': len(results),
                'success_count': sum(1 for r in results.values() if r['status'] == 'success'),
                'failed_count': len(results) - sum(1 for r in results.values() if r['status'] == 'success'),
                'results': results
            }
            
            # ä¿å­˜æŠ¥å‘Š
            report_file = os.path.join(self.features_dir, f'feature_build_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json')
            import json
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            
            print(f"\nðŸ“‹ ç‰¹å¾æž„å»ºæŠ¥å‘Šå·²ä¿å­˜: {report_file}")
            
        except Exception as e:
            print(f"âŒ ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
    
    def get_feature_summary(self):
        """èŽ·å–ç‰¹å¾æ‘˜è¦"""
        print("ðŸ“Š ç‰¹å¾æ‘˜è¦")
        print("=" * 60)
        
        if not os.path.exists(self.features_dir):
            print("âŒ ç‰¹å¾ç›®å½•ä¸å­˜åœ¨")
            return
        
        stock_dirs = [d for d in os.listdir(self.features_dir) if os.path.isdir(os.path.join(self.features_dir, d))]
        
        if not stock_dirs:
            print("âŒ æ²¡æœ‰ç‰¹å¾æ•°æ®")
            return
        
        print(f"ðŸ“ ç‰¹å¾æ•°æ® ({len(stock_dirs)} åªè‚¡ç¥¨):")
        
        for stock_dir in sorted(stock_dirs):
            stock_path = os.path.join(self.features_dir, stock_dir)
            files = [f for f in os.listdir(stock_path) if f.endswith('.csv')]
            
            if files:
                # èŽ·å–æœ€æ–°æ–‡ä»¶çš„ä¿¡æ¯
                latest_file = max(files, key=lambda x: os.path.getctime(os.path.join(stock_path, x)))
                file_path = os.path.join(stock_path, latest_file)
                
                try:
                    df = pd.read_csv(file_path, index_col=0, parse_dates=True)
                    print(f"   {stock_dir}: {len(df.columns)} ä¸ªç‰¹å¾, {len(df)} æ¡è®°å½•")
                    print(f"      æ—¶é—´èŒƒå›´: {df.index.min().strftime('%Y-%m-%d')} åˆ° {df.index.max().strftime('%Y-%m-%d')}")
                except:
                    print(f"   {stock_dir}: æ–‡ä»¶è¯»å–å¤±è´¥")

def main():
    """ä¸»å‡½æ•°"""
    print("ðŸ”§ ç‰¹å¾å·¥ç¨‹æ¨¡å—")
    print("=" * 60)
    
    # åˆ›å»ºç‰¹å¾å·¥ç¨‹å¸ˆ
    fe = FeatureEngineer()
    
    print("ðŸ”§ ç³»ç»ŸçŠ¶æ€:")
    print(f"   æ•°æ®ç›®å½•: {os.path.abspath(fe.data_dir)}")
    print(f"   ç‰¹å¾ç›®å½•: {os.path.abspath(fe.features_dir)}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ¸…æ´—åŽçš„æ•°æ®
    cleaned_dir = os.path.join(fe.data_dir, 'cleaned')
    if not os.path.exists(cleaned_dir):
        print("\nâŒ æ²¡æœ‰æ‰¾åˆ°æ¸…æ´—åŽçš„æ•°æ®ç›®å½•!")
        print("   è¯·å…ˆè¿è¡Œæ•°æ®èŽ·å–æ¨¡å—ä¸‹è½½æ•°æ®")
        return
    
    # èŽ·å–å¯ç”¨çš„è‚¡ç¥¨
    stock_dirs = [d for d in os.listdir(cleaned_dir) if os.path.isdir(os.path.join(cleaned_dir, d))]
    
    if not stock_dirs:
        print("\nâŒ æ²¡æœ‰æ‰¾åˆ°è‚¡ç¥¨æ•°æ®!")
        print("   è¯·å…ˆè¿è¡Œæ•°æ®èŽ·å–æ¨¡å—ä¸‹è½½æ•°æ®")
        return
    
    print(f"\nðŸ“Š å‘çŽ° {len(stock_dirs)} åªè‚¡ç¥¨çš„æ•°æ®:")
    for stock_dir in stock_dirs:
        print(f"   â€¢ {stock_dir}")
    
    # å¼€å§‹æž„å»ºç‰¹å¾
    print(f"\nðŸš€ å¼€å§‹æž„å»ºç‰¹å¾...")
    results = fe.batch_build_features(stock_list=stock_dirs)
    
    # æ˜¾ç¤ºç‰¹å¾æ‘˜è¦
    print(f"\nðŸ“Š ç‰¹å¾æž„å»ºå®Œæˆï¼ŒæŸ¥çœ‹æ‘˜è¦:")
    fe.get_feature_summary()

if __name__ == "__main__":
    main()
