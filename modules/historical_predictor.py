# -*- coding: utf-8 -*-
"""
å†å²é¢„æµ‹éªŒè¯å™¨
ç”¨äºåœ¨å†å²æ•°æ®ä¸ŠéªŒè¯æ¨¡å‹æ•ˆæœï¼Œä¸æ˜¯çœŸæ­£çš„æœªæ¥é¢„æµ‹
"""

import os
import pandas as pd
import numpy as np
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

from modules.model_trainer import ModelTrainer


class HistoricalPredictor:
    """å†å²é¢„æµ‹éªŒè¯å™¨ - åœ¨å†å²æ•°æ®ä¸ŠéªŒè¯æ¨¡å‹æ•ˆæœ"""
    
    def __init__(self, features_dir, models_dir, results_dir):
        self.features_dir = features_dir
        self.models_dir = models_dir
        self.results_dir = results_dir
        self.prediction_history = {}
        
        # é»˜è®¤æ—¶é—´åˆ’åˆ†é…ç½®ï¼ˆä¸ModelTrainerä¿æŒä¸€è‡´ï¼‰
        self.default_time_config = {
            'training_start': '2021-01-01',    # è®­ç»ƒå¼€å§‹æ—¶é—´
            'training_end': '2024-12-31',      # è®­ç»ƒç»“æŸæ—¶é—´
            'validation_start': '2025-01-01',  # éªŒè¯å¼€å§‹æ—¶é—´ï¼ˆé»˜è®¤ï¼‰
            'validation_end': '2025-12-31',    # éªŒè¯ç»“æŸæ—¶é—´ï¼ˆé»˜è®¤ï¼‰
        }
        
        # åˆ›å»ºå¿…è¦çš„ç›®å½•
        os.makedirs(results_dir, exist_ok=True)
        os.makedirs(os.path.join(results_dir, 'reports'), exist_ok=True)
    
    def load_model(self, stock_code):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        model_dir = os.path.join(self.models_dir, stock_code)
        if not os.path.exists(model_dir):
            raise FileNotFoundError(f"æœªæ‰¾åˆ°æ¨¡å‹ç›®å½•: {stock_code}")
        
        # æŸ¥æ‰¾æœ€æ–°çš„æ¨¡å‹æ–‡ä»¶
        model_files = [f for f in os.listdir(model_dir) if f.endswith('.pkl') and 'model' in f]
        if not model_files:
            raise FileNotFoundError(f"æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {stock_code}")
        
        latest_model = sorted(model_files)[-1]
        model_path = os.path.join(model_dir, latest_model)
        
        # åŠ è½½æ¨¡å‹
        import joblib
        model = joblib.load(model_path)
        
        # æŸ¥æ‰¾å¯¹åº”çš„æ ‡å‡†åŒ–å™¨
        scaler_files = [f for f in os.listdir(model_dir) if f.endswith('.pkl') and 'scaler' in f]
        scaler = None
        if scaler_files:
            latest_scaler = sorted(scaler_files)[-1]
            scaler_path = os.path.join(model_dir, latest_scaler)
            scaler = joblib.load(scaler_path)
        
        # æŸ¥æ‰¾æ¨¡å‹ä¿¡æ¯æ–‡ä»¶
        info_files = [f for f in os.listdir(model_dir) if f.endswith('.json') and 'info' in f]
        model_info = {}
        if info_files:
            latest_info = sorted(info_files)[-1]
            info_path = os.path.join(model_dir, latest_info)
            import json
            with open(info_path, 'r', encoding='utf-8') as f:
                model_info = json.load(f)
        
        return model, scaler, model_info
    
    def load_features(self, stock_code):
        """åŠ è½½ç‰¹å¾æ•°æ®"""
        stock_dir = os.path.join(self.features_dir, stock_code)
        if not os.path.exists(stock_dir):
            raise FileNotFoundError(f"æœªæ‰¾åˆ°ç‰¹å¾ç›®å½•: {stock_code}")
        
        # æŸ¥æ‰¾æœ€æ–°çš„ç‰¹å¾æ–‡ä»¶
        feature_files = [f for f in os.listdir(stock_dir) if f.endswith('.csv') and 'features' in f]
        if not feature_files:
            raise FileNotFoundError(f"æœªæ‰¾åˆ°ç‰¹å¾æ–‡ä»¶: {stock_code}")
        
        latest_file = sorted(feature_files)[-1]
        file_path = os.path.join(stock_dir, latest_file)
        
        print(f"ğŸ“‚ åŠ è½½ç‰¹å¾: {os.path.basename(latest_file)}")
        
        try:
            feat = pd.read_csv(file_path, index_col=0, parse_dates=True)
            print(f"   âœ… ç‰¹å¾åŠ è½½æˆåŠŸ: {len(feat)} æ¡è®°å½•")
            print(f"   ğŸ“… æ•°æ®æ—¶é—´èŒƒå›´: {feat.index.min().strftime('%Y-%m-%d')} åˆ° {feat.index.max().strftime('%Y-%m-%d')}")
            return feat
        except Exception as e:
            raise Exception(f"ç‰¹å¾åŠ è½½å¤±è´¥: {e}")
    
    def validate_historical_predictions(self, stock_code, start_date=None, end_date=None):
        """åœ¨å†å²æ•°æ®ä¸ŠéªŒè¯æ¨¡å‹æ•ˆæœï¼Œé»˜è®¤ä½¿ç”¨2025å¹´æ•°æ®"""
        print(f"ğŸ” å†å²é¢„æµ‹éªŒè¯: {stock_code}")
        print("=" * 60)
        
        # ä½¿ç”¨é»˜è®¤éªŒè¯æ—¶é—´ï¼ˆ2025å¹´ï¼‰
        if start_date is None:
            start_date = self.default_time_config['validation_start']
        if end_date is None:
            end_date = self.default_time_config['validation_end']
        
        print(f"ğŸ“… éªŒè¯æ—¶é—´èŒƒå›´: {start_date} åˆ° {end_date}")
        print(f"ğŸ’¡ è¿™æ˜¯æ¨¡å‹è®­ç»ƒæ—¶å®Œå…¨æœªä½¿ç”¨çš„æ•°æ®ï¼Œç”¨äºéªŒè¯æ¨¡å‹æ•ˆæœ")
        
        try:
            # 1. åŠ è½½æ¨¡å‹
            model, scaler, model_info = self.load_model(stock_code)
            
            # 2. åŠ è½½ç‰¹å¾æ•°æ®
            feat = self.load_features(stock_code)
            
            # 3. åº”ç”¨æ—¥æœŸè¿‡æ»¤
            start_date = pd.to_datetime(start_date)
            end_date = pd.to_datetime(end_date)
            
            # ç¡®ä¿æ•°æ®åœ¨æŒ‡å®šèŒƒå›´å†…
            available_start = feat.index.min()
            available_end = feat.index.max()
            
            if start_date < available_start:
                print(f"âš ï¸  è¯·æ±‚çš„å¼€å§‹æ—¶é—´ {start_date.strftime('%Y-%m-%d')} æ—©äºå¯ç”¨æ•°æ® {available_start.strftime('%Y-%m-%d')}ï¼Œä½¿ç”¨å¯ç”¨æ•°æ®å¼€å§‹æ—¶é—´")
                start_date = available_start
            
            if end_date > available_end:
                print(f"âš ï¸  è¯·æ±‚çš„ç»“æŸæ—¶é—´ {end_date.strftime('%Y-%m-%d')} æ™šäºå¯ç”¨æ•°æ® {available_end.strftime('%Y-%m-%d')}ï¼Œä½¿ç”¨å¯ç”¨æ•°æ®ç»“æŸæ—¶é—´")
                end_date = available_end
            
            # è¿‡æ»¤éªŒè¯æ•°æ®
            validation_data = feat[(feat.index >= start_date) & (feat.index <= end_date)].copy()
            
            if len(validation_data) == 0:
                raise ValueError(f"åœ¨æŒ‡å®šæ—¶é—´èŒƒå›´å†…æ²¡æœ‰æ‰¾åˆ°æ•°æ®: {start_date.strftime('%Y-%m-%d')} åˆ° {end_date.strftime('%Y-%m-%d')}")
            
            print(f"ğŸ“ˆ éªŒè¯æ•°æ®: {len(validation_data)} æ¡è®°å½•")
            print(f"ğŸ“… å®é™…éªŒè¯èŒƒå›´: {validation_data.index.min().strftime('%Y-%m-%d')} åˆ° {validation_data.index.max().strftime('%Y-%m-%d')}")
            
            # 4. å‡†å¤‡éªŒè¯æ•°æ®
            feature_cols = model_info['feature_names']
            
            # æ£€æŸ¥ç‰¹å¾æ˜¯å¦åŒ¹é…
            missing_features = set(feature_cols) - set(validation_data.columns)
            if missing_features:
                raise ValueError(f"ç¼ºå°‘ç‰¹å¾: {missing_features}")
            
            X_new = validation_data[feature_cols].values
            
            # ç§»é™¤åŒ…å«NaNçš„è¡Œ
            valid_mask = ~np.isnan(X_new).any(axis=1)
            X_new = X_new[valid_mask]
            validation_data_valid = validation_data[valid_mask].copy()
            
            print(f"ğŸ” æœ‰æ•ˆéªŒè¯æ•°æ®: {len(validation_data_valid)} æ¡è®°å½•")
            print(f"ğŸ“Š ç‰¹å¾ç»´åº¦: {X_new.shape}")
            
            # 5. æ ‡å‡†åŒ–å’Œé¢„æµ‹
            print("ğŸ¤– è¿›è¡Œå†å²éªŒè¯...")
            X_new_scaled = scaler.transform(X_new)
            predictions = model.predict(X_new_scaled)
            probabilities = model.predict_proba(X_new_scaled)
            
            # 6. æ·»åŠ é¢„æµ‹ç»“æœåˆ°æ•°æ®
            validation_data_valid['pred_label'] = predictions
            validation_data_valid['pred_prob'] = probabilities[:, 1]  # ä¸Šæ¶¨æ¦‚ç‡
            
            # 7. åˆ†æéªŒè¯ç»“æœ
            self._analyze_validation_results(stock_code, validation_data_valid, model_info)
            
            # 8. ç”Ÿæˆå†å²äº¤æ˜“ä¿¡å·
            signals = self._generate_historical_signals(validation_data_valid)
            
            # 9. ä¿å­˜éªŒè¯ç»“æœ
            self.prediction_history[stock_code] = {
                'predictions': validation_data_valid,
                'signals': signals,
                'model_info': model_info,
                'validation_date': datetime.now().strftime("%Y%m%d_%H%M%S"),
                'validation_period': {
                    'start': start_date.strftime('%Y-%m-%d'),
                    'end': end_date.strftime('%Y-%m-%d'),
                    'samples': len(validation_data_valid)
                }
            }
            
            return validation_data_valid, signals
            
        except Exception as e:
            print(f"âŒ å†å²éªŒè¯å¤±è´¥: {e}")
            return None, None
    
    def _analyze_validation_results(self, stock_code, validation_data, model_info):
        """åˆ†æå†å²éªŒè¯ç»“æœ"""
        print(f"\nğŸ“Š å†å²éªŒè¯ç»“æœåˆ†æ: {stock_code}")
        print("-" * 50)
        
        # 1. åŸºæœ¬ç»Ÿè®¡
        total_samples = len(validation_data)
        avg_probability = np.mean(validation_data['pred_prob'])
        label_distribution = np.bincount(validation_data['pred_label'])
        
        print(f"ğŸ“ˆ åŸºæœ¬ç»Ÿè®¡:")
        print(f"   éªŒè¯æ ·æœ¬æ•°: {total_samples}")
        print(f"   å¹³å‡é¢„æµ‹æ¦‚ç‡: {avg_probability:.3f}")
        print(f"   é¢„æµ‹ä¸Šæ¶¨: {label_distribution[1]} ({label_distribution[1]/total_samples:.1%})")
        print(f"   é¢„æµ‹ä¸‹è·Œ: {label_distribution[0]} ({label_distribution[0]/total_samples:.1%})")
        
        # 2. æ¦‚ç‡åˆ†å¸ƒåˆ†æ
        high_confidence_up = np.sum(validation_data['pred_prob'] > 0.7)
        high_confidence_down = np.sum(validation_data['pred_prob'] < 0.3)
        medium_confidence = np.sum((validation_data['pred_prob'] >= 0.3) & (validation_data['pred_prob'] <= 0.7))
        
        print(f"\nğŸ¯ ç½®ä¿¡åº¦åˆ†æ:")
        print(f"   é«˜ç½®ä¿¡åº¦ä¸Šæ¶¨ (>0.7): {high_confidence_up} ({high_confidence_up/total_samples:.1%})")
        print(f"   é«˜ç½®ä¿¡åº¦ä¸‹è·Œ (<0.3): {high_confidence_down} ({high_confidence_down/total_samples:.1%})")
        print(f"   ä¸­ç­‰ç½®ä¿¡åº¦ (0.3-0.7): {medium_confidence} ({medium_confidence/total_samples:.1%})")
        
        # 3. æ—¶é—´åºåˆ—åˆ†æ
        recent_predictions = validation_data.tail(20)  # æœ€è¿‘20ä¸ªé¢„æµ‹
        recent_avg_prob = np.mean(recent_predictions['pred_prob'])
        recent_trend = "ä¸Šæ¶¨" if recent_avg_prob > avg_probability else "ä¸‹è·Œ"
        
        print(f"\nâ° è¿‘æœŸè¶‹åŠ¿:")
        print(f"   æœ€è¿‘20ä¸ªé¢„æµ‹å¹³å‡æ¦‚ç‡: {recent_avg_prob:.3f}")
        print(f"   æ•´ä½“è¶‹åŠ¿: {recent_trend}")
        
        # 4. ä¸è®­ç»ƒæ•°æ®çš„å¯¹æ¯”
        if 'data_info' in model_info:
            training_info = model_info['data_info']
            print(f"\nğŸ“š ä¸è®­ç»ƒæ•°æ®å¯¹æ¯”:")
            print(f"   è®­ç»ƒæ ·æœ¬æ•°: {training_info.get('training_samples', 'N/A')}")
            print(f"   æµ‹è¯•æ ·æœ¬æ•°: {training_info.get('test_samples', 'N/A')}")
            print(f"   ç‰¹å¾æ•°é‡: {training_info.get('feature_count', 'N/A')}")
            print(f"   è®­ç»ƒæ—¶é—´: {training_info.get('training_start', 'N/A')} åˆ° {training_info.get('training_end', 'N/A')}")
    
    def _generate_historical_signals(self, validation_data, buy_threshold=0.6, sell_threshold=0.4):
        """ç”Ÿæˆå†å²äº¤æ˜“ä¿¡å·"""
        print(f"\nğŸš¦ ç”Ÿæˆå†å²äº¤æ˜“ä¿¡å·...")
        
        signals = []
        
        for i, row in validation_data.iterrows():
            prob = row['pred_prob']
            date = row.name
            
            if prob > buy_threshold:
                signal = {
                    'date': date,
                    'action': 'BUY',
                    'confidence': prob,
                    'reason': f'å†å²éªŒè¯ä¸Šæ¶¨æ¦‚ç‡: {prob:.3f} > {buy_threshold}'
                }
                signals.append(signal)
            elif prob < sell_threshold:
                signal = {
                    'date': date,
                    'action': 'SELL',
                    'confidence': 1 - prob,
                    'reason': f'å†å²éªŒè¯ä¸‹è·Œæ¦‚ç‡: {1-prob:.3f} > {1-sell_threshold}'
                }
                signals.append(signal)
            else:
                signal = {
                    'date': date,
                    'action': 'HOLD',
                    'confidence': 0.5,
                    'reason': f'å†å²éªŒè¯æ¦‚ç‡: {prob:.3f}ï¼Œå»ºè®®è§‚æœ›'
                }
                signals.append(signal)
        
        # ç»Ÿè®¡ä¿¡å·
        buy_signals = [s for s in signals if s['action'] == 'BUY']
        sell_signals = [s for s in signals if s['action'] == 'SELL']
        hold_signals = [s for s in signals if s['action'] == 'HOLD']
        
        print(f"ğŸ“Š å†å²äº¤æ˜“ä¿¡å·ç»Ÿè®¡:")
        print(f"   ä¹°å…¥ä¿¡å·: {len(buy_signals)} ä¸ª")
        print(f"   å–å‡ºä¿¡å·: {len(sell_signals)} ä¸ª")
        print(f"   è§‚æœ›ä¿¡å·: {len(hold_signals)} ä¸ª")
        
        return signals
    
    def save_validation_summary(self, filename=None):
        """ä¿å­˜å†å²éªŒè¯ç»“æœæ‘˜è¦"""
        if not self.prediction_history:
            print("âŒ æ²¡æœ‰éªŒè¯ç»“æœå¯ä¿å­˜")
            return
        
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"historical_validation_summary_{timestamp}.json"
        
        # å‡†å¤‡ä¿å­˜çš„æ•°æ®
        save_data = {}
        for stock, data in self.prediction_history.items():
            save_data[stock] = {
                'validation_date': data['validation_date'],
                'validation_period': data['validation_period'],
                'model_info': {
                    'training_date': data['model_info'].get('training_date', 'Unknown'),
                    'feature_names': data['model_info'].get('feature_names', []),
                    'cv_scores': data['model_info'].get('cv_scores', {}),
                    'training_metrics': data['model_info'].get('training_metrics', {}),
                    'data_info': data['model_info'].get('data_info', {})
                },
                'validation_summary': {
                    'total_samples': len(data['predictions']),
                    'avg_probability': float(np.mean(data['predictions']['pred_prob'])),
                    'label_distribution': data['predictions']['pred_label'].value_counts().to_dict()
                },
                'signals_summary': {
                    'buy_signals': len([s for s in data['signals'] if s['action'] == 'BUY']),
                    'sell_signals': len([s for s in data['signals'] if s['action'] == 'SELL']),
                    'hold_signals': len([s for s in data['signals'] if s['action'] == 'HOLD'])
                }
            }
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        filepath = os.path.join(self.results_dir, 'reports', filename)
        import json
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(save_data, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"ğŸ’¾ å†å²éªŒè¯æ‘˜è¦å·²ä¿å­˜: {filename}")
    
    def batch_validate_historical(self, stock_list=None, start_date=None, end_date=None):
        """æ‰¹é‡éªŒè¯å¤šä¸ªè‚¡ç¥¨çš„å†å²é¢„æµ‹"""
        if stock_list is None:
            # ä»ç‰¹å¾ç›®å½•è·å–è‚¡ç¥¨åˆ—è¡¨
            if os.path.exists(self.features_dir):
                stock_list = [d for d in os.listdir(self.features_dir) if os.path.isdir(os.path.join(self.features_dir, d))]
            else:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°ç‰¹å¾ç›®å½•")
                return {}
        
        if not stock_list:
            print("âŒ æ²¡æœ‰è‚¡ç¥¨å¯éªŒè¯")
            return {}
        
        print(f"ğŸ” æ‰¹é‡å†å²éªŒè¯: {len(stock_list)} åªè‚¡ç¥¨")
        print("=" * 60)
        print(f"ğŸ“… é»˜è®¤éªŒè¯æ—¶é—´: {self.default_time_config['validation_start']} åˆ° {self.default_time_config['validation_end']}")
        print(f"ğŸ’¡ è¿™æ˜¯æ¨¡å‹è®­ç»ƒæ—¶å®Œå…¨æœªä½¿ç”¨çš„æ•°æ®ï¼Œç”¨äºéªŒè¯æ¨¡å‹æ•ˆæœ")
        print("=" * 60)
        
        results = {}
        
        for i, stock_code in enumerate(stock_list, 1):
            print(f"\nğŸ“Š [{i}/{len(stock_list)}] éªŒè¯è‚¡ç¥¨: {stock_code}")
            print("-" * 40)
            
            try:
                feat_pred, signals = self.validate_historical_predictions(stock_code, start_date, end_date)
                
                if feat_pred is not None:
                    results[stock_code] = {
                        'success': True,
                        'samples': len(feat_pred),
                        'signals': len(signals),
                        'validation_period': self.prediction_history[stock_code]['validation_period']
                    }
                else:
                    results[stock_code] = {
                        'success': False,
                        'error': 'éªŒè¯å¤±è´¥'
                    }
                    
            except Exception as e:
                print(f"âŒ {stock_code}: éªŒè¯å¼‚å¸¸ - {e}")
                results[stock_code] = {
                    'success': False,
                    'error': str(e)
                }
        
        return results
